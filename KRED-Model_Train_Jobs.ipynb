{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import time\n",
    "import torch\n",
    "import os\n",
    "from utils.util_jobs import *\n",
    "from train_test import *\n",
    "import argparse\n",
    "from parse_config import ConfigParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Config Loading\n",
    "parser = argparse.ArgumentParser(description='KRED')\n",
    "parser.add_argument('-f')\n",
    "parser.add_argument('-c', '--config', default=\"./config.json\", type=str,\n",
    "                    help='config file path (default: None)')\n",
    "parser.add_argument('-r', '--resume', default=None, type=str,\n",
    "                    help='path to latest checkpoint (default: None)')\n",
    "parser.add_argument('-d', '--device', default=None, type=str,\n",
    "                    help='indices of GPUs to enable (default: all)')\n",
    "\n",
    "config = ConfigParser.from_args(parser)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from utils.util_jobs import load_pretrained_data_mind_jobs\n",
    "data = load_pretrained_data_mind_jobs(config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training\n",
      "Training epoch 0/6 - 0.0\n",
      "######\n",
      " Step: 0, 0.0 \n",
      "######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J:\\Downloads\\NLP\\kred\\model\\KGAT.py:156: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neighbor_entity_embedding = entity_embedding_lookup(torch.tensor(neighbor_entities).cuda())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######\n",
      " Step: 100, 0.14326647564469913 \n",
      "######\n",
      "######\n",
      " Step: 200, 0.28653295128939826 \n",
      "######\n",
      "######\n",
      " Step: 300, 0.4297994269340974 \n",
      "######\n",
      "######\n",
      " Step: 400, 0.5730659025787965 \n",
      "######\n",
      "######\n",
      " Step: 500, 0.7163323782234957 \n",
      "######\n",
      "######\n",
      " Step: 600, 0.8595988538681948 \n",
      "######\n",
      "all loss: tensor(246.8292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "_train_epoch\n",
      "auc socre: 0.8458348443019172\n",
      "valid_socre\n",
      "valid_scores\n",
      "early_stopping\n",
      "Saving checkpoint: out\\saved\\models\\KRED\\0215_170343\\checkpoint-model-epoch1.pth ...\n",
      "epoch % self.save_period\n",
      "Training epoch 1/6 - 0.16666666666666666\n",
      "######\n",
      " Step: 0, 0.0 \n",
      "######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J:\\Downloads\\NLP\\kred\\model\\KGAT.py:156: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neighbor_entity_embedding = entity_embedding_lookup(torch.tensor(neighbor_entities).cuda())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######\n",
      " Step: 100, 0.14326647564469913 \n",
      "######\n",
      "######\n",
      " Step: 200, 0.28653295128939826 \n",
      "######\n",
      "######\n",
      " Step: 300, 0.4297994269340974 \n",
      "######\n",
      "######\n",
      " Step: 400, 0.5730659025787965 \n",
      "######\n",
      "######\n",
      " Step: 500, 0.7163323782234957 \n",
      "######\n",
      "######\n",
      " Step: 600, 0.8595988538681948 \n",
      "######\n",
      "all loss: tensor(166.7045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "_train_epoch\n",
      "auc socre: 0.8730194041583211\n",
      "valid_socre\n",
      "valid_scores\n",
      "early_stopping\n",
      "Saving checkpoint: out\\saved\\models\\KRED\\0215_170343\\checkpoint-model-epoch2.pth ...\n",
      "epoch % self.save_period\n",
      "Training epoch 2/6 - 0.3333333333333333\n",
      "######\n",
      " Step: 0, 0.0 \n",
      "######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J:\\Downloads\\NLP\\kred\\model\\KGAT.py:156: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neighbor_entity_embedding = entity_embedding_lookup(torch.tensor(neighbor_entities).cuda())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######\n",
      " Step: 100, 0.14326647564469913 \n",
      "######\n",
      "######\n",
      " Step: 200, 0.28653295128939826 \n",
      "######\n",
      "######\n",
      " Step: 300, 0.4297994269340974 \n",
      "######\n",
      "######\n",
      " Step: 400, 0.5730659025787965 \n",
      "######\n",
      "######\n",
      " Step: 500, 0.7163323782234957 \n",
      "######\n",
      "######\n",
      " Step: 600, 0.8595988538681948 \n",
      "######\n",
      "all loss: tensor(156.2760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "_train_epoch\n",
      "auc socre: 0.8794767831898198\n",
      "valid_socre\n",
      "valid_scores\n",
      "early_stopping\n",
      "Saving checkpoint: out\\saved\\models\\KRED\\0215_170343\\checkpoint-model-epoch3.pth ...\n",
      "epoch % self.save_period\n",
      "Training epoch 3/6 - 0.5\n",
      "######\n",
      " Step: 0, 0.0 \n",
      "######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J:\\Downloads\\NLP\\kred\\model\\KGAT.py:156: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neighbor_entity_embedding = entity_embedding_lookup(torch.tensor(neighbor_entities).cuda())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######\n",
      " Step: 100, 0.14326647564469913 \n",
      "######\n",
      "######\n",
      " Step: 200, 0.28653295128939826 \n",
      "######\n",
      "######\n",
      " Step: 300, 0.4297994269340974 \n",
      "######\n",
      "######\n",
      " Step: 400, 0.5730659025787965 \n",
      "######\n",
      "######\n",
      " Step: 500, 0.7163323782234957 \n",
      "######\n",
      "######\n",
      " Step: 600, 0.8595988538681948 \n",
      "######\n",
      "all loss: tensor(147.0551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "_train_epoch\n",
      "auc socre: 0.8717625988070684\n",
      "valid_socre\n",
      "valid_scores\n",
      "early_stopping\n",
      "Saving checkpoint: out\\saved\\models\\KRED\\0215_170343\\checkpoint-model-epoch4.pth ...\n",
      "epoch % self.save_period\n",
      "Training epoch 4/6 - 0.6666666666666666\n",
      "######\n",
      " Step: 0, 0.0 \n",
      "######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J:\\Downloads\\NLP\\kred\\model\\KGAT.py:156: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neighbor_entity_embedding = entity_embedding_lookup(torch.tensor(neighbor_entities).cuda())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######\n",
      " Step: 100, 0.14326647564469913 \n",
      "######\n",
      "######\n",
      " Step: 200, 0.28653295128939826 \n",
      "######\n",
      "######\n",
      " Step: 300, 0.4297994269340974 \n",
      "######\n",
      "######\n",
      " Step: 400, 0.5730659025787965 \n",
      "######\n",
      "######\n",
      " Step: 500, 0.7163323782234957 \n",
      "######\n",
      "######\n",
      " Step: 600, 0.8595988538681948 \n",
      "######\n",
      "all loss: tensor(139.5108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "_train_epoch\n",
      "auc socre: 0.8601487989984626\n",
      "valid_socre\n",
      "valid_scores\n",
      "early_stopping\n",
      "Saving checkpoint: out\\saved\\models\\KRED\\0215_170343\\checkpoint-model-epoch5.pth ...\n",
      "epoch % self.save_period\n"
     ]
    }
   ],
   "source": [
    "if config['trainer']['training_type'] == \"single_task\":\n",
    "    single_task_training(config, data)\n",
    "else:\n",
    "    multi_task_training(config, data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J:\\Downloads\\NLP\\kred\\model\\KGAT.py:156: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neighbor_entity_embedding = entity_embedding_lookup(torch.tensor(neighbor_entities).cuda())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "zero error\n",
      "auc score:0.8601487989984626\n",
      "ndcg score:0.6794746818941608\n"
     ]
    }
   ],
   "source": [
    "test_data = data[-1]\n",
    "testing(test_data, config)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
