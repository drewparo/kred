{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3sO-W_lWk5q6",
    "outputId": "a85eaa73-15c1-4fbf-a49b-ae0a3f79b47f"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TS-IfvNmk4C4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import torch\n",
    "import requests\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DCEEdW8ubRRh"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./adressa/mind_format/train/wikidata_ids.txt', header=None, names=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uJvpf0vVbg9v"
   },
   "outputs": [],
   "source": [
    "# List of all the entities\n",
    "entity_ids = [r[0] for r in df.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wJ_NyHytDQG1"
   },
   "outputs": [],
   "source": [
    "# Function to create entities/relation to id variables\n",
    "def create_x2id_dict(elements):\n",
    "  result = {}\n",
    "  for e in elements:\n",
    "    result[e] = len(result)\n",
    "\n",
    "  return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hYLzUoCGtOQH"
   },
   "outputs": [],
   "source": [
    "def get_description(id):\n",
    "    query = f\"\"\"\n",
    "    SELECT ?Label ?Description\n",
    "    WHERE \n",
    "    {{\n",
    "      wd:{id} rdfs:label ?Label .\n",
    "      FILTER (LANG(?Label) = \"en\").\n",
    "      OPTIONAL {{ wd:{id} schema:description ?Description . FILTER (LANG(?Description) = \"en\") }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    max_tries = 100\n",
    "    for i in range(max_tries):\n",
    "      try:\n",
    "        response = requests.get(\"https://query.wikidata.org/sparql\", params={'query': query, 'format': 'json'})\n",
    "        response_json = response.json()\n",
    "        label = response_json['results']['bindings'][0]['Label']['value']\n",
    "        description = response_json['results']['bindings'][0].get('Description', {}).get('value', '')\n",
    "        description = label + ' ' + description\n",
    "        return description\n",
    "      except:\n",
    "        pass\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOLIpgCTk4C8"
   },
   "outputs": [],
   "source": [
    "# Load the pre-trained language model and its tokenizer\n",
    "model = SentenceTransformer('all-mpnet-base-v2').to('cuda:0')\n",
    "global bad_entities\n",
    "bad_entities = []\n",
    "# Define a function to extract the embeddings for a given entity\n",
    "def extract_embeddings(entity_id, model):\n",
    "    # Get the text description for the entity\n",
    "    entity_description = get_description(entity_id)\n",
    "    if entity_description == None:\n",
    "        bad_entities.append(entity_id)\n",
    "        return None, None\n",
    "\n",
    "    sentence_embeddings = model.encode(entity_description)\n",
    "    \n",
    "    return entity_description, sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xJ1FBol71A4p",
    "outputId": "69729565-af02-4dce-d832-6b3642e50168"
   },
   "outputs": [],
   "source": [
    "# Extract the embeddings for each entity\n",
    "entity_embeddings = []\n",
    "entities_descriptions = []\n",
    "for entity_id in tqdm(entity_ids):\n",
    "    entity_description, sentence_embeddings = extract_embeddings(entity_id, model)\n",
    "    entity_embeddings.append(sentence_embeddings)\n",
    "    entities_descriptions.append(entity_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_embeddings = []\n",
    "for entity_des in tqdm(entity_ids):\n",
    "    if entity_des is None:\n",
    "        entity_embeddings.append()\n",
    "    else:\n",
    "        phrase_emb = model.encode(entity_des)\n",
    "        entity_embeddings.append(phrase_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp File to avoid to load all entities\n",
    "with open('description.txt', 'w') as fp:\n",
    "    for line in entities_descriptions:\n",
    "        fp.write(str(line)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MU7wBPNaDbBq"
   },
   "outputs": [],
   "source": [
    "entity_ids = [e for e in entity_ids if e not in bad_entities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dfKKvQSkDXHA"
   },
   "outputs": [],
   "source": [
    "entity2id_dict = create_x2id_dict(entity_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kg_folder_adressa = './adressa/kg/'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wbI2uJkAys0R"
   },
   "outputs": [],
   "source": [
    "with open(kg_folder_adressa+ 'entity2id.txt', 'w', newline='') as file:\n",
    "    writer = csv.writer(file, delimiter='\\t')\n",
    "    for key, value in entity2id_dict.items():\n",
    "        writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RGy1WEBblMQF"
   },
   "outputs": [],
   "source": [
    "entity_embeddings = [list(embedding) for embedding in entity_embeddings if not embedding is None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3WrDTFQrwgZl"
   },
   "outputs": [],
   "source": [
    "np.savetxt(kg_folder_adressa+'entity2vecd768.vec', entity_embeddings, fmt='%.6f', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L79cfJV5V30k"
   },
   "outputs": [],
   "source": [
    "chunks = [entity_ids[x:x+100] for x in range(0, len(entity_ids), 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v_ErfY46Xz1Z",
    "outputId": "b09ebb81-db01-40e2-fdd1-beada7f5fd89"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define the API endpoint for retrieving information about entities\n",
    "endpoint = \"https://www.wikidata.org/w/api.php\"\n",
    "\n",
    "chunks = [entity_ids[x:x+50] for x in range(0, len(entity_ids), 50)]\n",
    "\n",
    "entities = {}\n",
    "\n",
    "for c in chunks:\n",
    "  # Define the parameters for the API request\n",
    "  params = {\n",
    "      \"action\": \"wbgetentities\",\n",
    "      \"ids\": \"|\".join(c),\n",
    "      \"format\": \"json\"\n",
    "  }\n",
    "\n",
    "  # Send the API request and retrieve the response\n",
    "  response = requests.get(endpoint, params=params)\n",
    "\n",
    "  # Extract the JSON data from the response\n",
    "  data = response.json()\n",
    "  #print(data)\n",
    "\n",
    "  # Define a dictionary to store the entity information\n",
    "  #entities = {}\n",
    "\n",
    "  # Extract the entity information from the data\n",
    "  for entity_id, entity in data[\"entities\"].items():\n",
    "      try:\n",
    "        entities[entity_id] = {\n",
    "            \"label\": entity[\"labels\"][\"en\"][\"value\"],\n",
    "            \"description\": entity[\"descriptions\"][\"en\"][\"value\"],\n",
    "            \"claims\": entity.get(\"claims\", {})\n",
    "        }\n",
    "      except:\n",
    "        entities[entity_id] = {\n",
    "            \"label\": entity[\"labels\"][\"en\"][\"value\"],\n",
    "            \"description\": entity[\"labels\"][\"en\"][\"value\"],\n",
    "            \"claims\": entity.get(\"claims\", {})\n",
    "        }\n",
    "\n",
    "# Define a list to store the relationships between entities\n",
    "relationships = []\n",
    "\n",
    "# Extract the relationships between entities from the entity information\n",
    "for entity_id, entity in entities.items():\n",
    "    for property_id, property_values in entity[\"claims\"].items():\n",
    "        for property_value in property_values:\n",
    "            if \"mainsnak\" in property_value and \"datavalue\" in property_value[\"mainsnak\"]:\n",
    "                datavalue = property_value[\"mainsnak\"][\"datavalue\"]\n",
    "                if \"value\" in datavalue and \"id\" in datavalue[\"value\"]:\n",
    "                    #print(datavalue)\n",
    "                    try:\n",
    "                      target_entity_id = datavalue[\"value\"][\"id\"]\n",
    "                      if target_entity_id in entity_ids:\n",
    "                        relationships.append((entity_id, property_id, target_entity_id))\n",
    "                    except:\n",
    "                      pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mpm08TuuX14y"
   },
   "outputs": [],
   "source": [
    "relations = list(set([rel[1] for rel in relationships]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afk-yaiaZZQN"
   },
   "outputs": [],
   "source": [
    "relation2id_dict = create_x2id_dict(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RpNsbi_TzLKe"
   },
   "outputs": [],
   "source": [
    "with open(kg_folder_adressa+'relation2id.txt', 'w', newline='') as file:\n",
    "    writer = csv.writer(file, delimiter='\\t')\n",
    "    for key, value in relation2id_dict.items():\n",
    "        writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0JTL5o1RaTEz",
    "outputId": "b8f62c2a-8756-4054-dd41-f92efff8a26d"
   },
   "outputs": [],
   "source": [
    "global bad_relations\n",
    "bad_relations = []\n",
    "\n",
    "def extract_embeddings_relation(relation_id, model):\n",
    "    relation_description = get_description(relation_id)\n",
    "    if relation_description == None:\n",
    "        bad_relations.append(relation_id)\n",
    "        return None, None\n",
    "    sentence_embeddings = model.encode(relation_description)\n",
    "    return relation_description, sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_embeddings = []\n",
    "relation_descs = []\n",
    "for relation_id in relations:\n",
    "    emb_, rela_d = extract_embeddings_relation(relation_id, model)\n",
    "    relation_embeddings.append(emb_)\n",
    "    relation_descs.append(rela_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ypgoqoPwyCVT"
   },
   "outputs": [],
   "source": [
    "relations = [r for r in relations if r not in bad_relations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fW_PknTAy_iw"
   },
   "outputs": [],
   "source": [
    "relation2id_dict = create_x2id_dict(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pLDm6YETzE7L"
   },
   "outputs": [],
   "source": [
    "with open(kg_folder_adressa+'relation2id.txt', 'w', newline='') as file:\n",
    "    writer = csv.writer(file, delimiter='\\t')\n",
    "    for key, value in relation2id_dict.items():\n",
    "        writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NC3wgPXUfTRH"
   },
   "outputs": [],
   "source": [
    "relation_embeddings = [list(embedding) for embedding in relation_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hl_vQNByzXXW"
   },
   "outputs": [],
   "source": [
    "np.savetxt(kg_folder_adressa+'relation2vecd768.vec', relation_embeddings, fmt='%.6f', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fIbF1DRHoas9"
   },
   "outputs": [],
   "source": [
    "relationships = list(set(relationships))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "klwshn5qo51d"
   },
   "outputs": [],
   "source": [
    "triple2id = [(entity2id_dict[relation[0]],entity2id_dict[relation[2]],relation2id_dict[relation[1]]) for relation in relationships]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jIENgLrfpscp"
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "triple2id = sorted(triple2id, key=itemgetter(0, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BeI7O0iVrrRn"
   },
   "outputs": [],
   "source": [
    "with open(kg_folder_adressa+'triple2id.txt', 'w', newline='') as file:\n",
    "    writer = csv.writer(file, delimiter='\\t')\n",
    "    for tuple_ in triple2id:\n",
    "        writer.writerow(tuple_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Reduce dimension using PCA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load the embeddings from the file specified in `path1`\n",
    "with open(kg_folder_adressa+'entity2vecd768.vec', 'r') as f:\n",
    "    embeddings = np.loadtxt(f, delimiter='\\t')\n",
    "\n",
    "# Apply PCA to the embeddings to reduce the dimensionality to 100\n",
    "pca = PCA(n_components=100)\n",
    "reduced_embeddings = pca.fit_transform(embeddings)\n",
    "np.savetxt(kg_folder_adressa+'entity2vecd100.vec', reduced_embeddings, fmt='%.6f', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(kg_folder_adressa+'relation2vecd768.vec', 'r') as f:\n",
    "    embeddings = np.loadtxt(f, delimiter='\\t')\n",
    "\n",
    "# Apply PCA to the embeddings to reduce the dimensionality to 100\n",
    "pca = PCA(n_components=100)\n",
    "reduced_embeddings = pca.fit_transform(embeddings)\n",
    "np.savetxt(kg_folder_adressa+'relation2vecd100.vec', reduced_embeddings, fmt='%.6f', delimiter='\\t')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
