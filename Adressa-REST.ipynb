{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/amazon-science/ReFinED.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading /root/.cache/refined/wikidata_data/qcode_to_idx.lmdb: 100%|██████████| 1.35G/1.35G [00:39<00:00, 34.4MB/s]\n",
      "Downloading /root/.cache/refined/wikidata_data/qcode_to_class_tns_33831487-200.np: 100%|██████████| 13.5G/13.5G [06:31<00:00, 34.6MB/s] \n",
      "Downloading /root/.cache/refined/wikidata_data/subclasses.lmdb: 100%|██████████| 120M/120M [00:03<00:00, 31.4MB/s] \n",
      "Downloading /root/.cache/refined/wikidata_data/qcode_to_wiki.lmdb: 100%|██████████| 580M/580M [00:17<00:00, 33.5MB/s] \n",
      "Downloading /root/.cache/refined/wikidata_data/nltk_sentence_splitter_english.pickle: 100%|██████████| 407k/407k [00:00<00:00, 2.58MB/s]\n",
      "Some weights of the model checkpoint at /root/.cache/refined/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /root/.cache/refined/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from refined.inference.processor import Refined\n",
    "refined = Refined.from_pretrained(\n",
    "    model_name='wikipedia_model',\n",
    "    entity_set=\"wikidata\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from refined.data_types.base_types import Entity, Span\n",
    "def spans_to_mind_format(results : Span):\n",
    "    entity_list = []\n",
    "    for entity in results:\n",
    "        if entity.predicted_entity.wikidata_entity_id == None:\n",
    "            continue\n",
    "            # An entity has been detected but does not have a wikidata page\n",
    "        entity_list.append({\n",
    "            'Label' : entity.predicted_entity.wikipedia_entity_title,\n",
    "            'Type': entity.coarse_mention_type,\n",
    "            'WikidataId': entity.predicted_entity.wikidata_entity_id,\n",
    "            'Confidence': entity.candidate_entities[0][1],\n",
    "            'OccurrenceOffsets': [entity.start],\n",
    "            'SurfaceForms': [entity.text]\n",
    "        })\n",
    "    return entity_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/890 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1794c5b376da4660b7d58c3caac59124"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/1.24G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79ea98751c7b4672b917541348641a78"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/3.54M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45b0897de33440529fd3bf751407b84a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/2.31M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "df00295ac9b84742a23c27590601e834"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/1.82k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b5585408358a447fa81d2265d9a71506"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/1.52k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd32e14b0b564056a30f54e43b09ac23"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'M2M100Tokenizer'. \n",
      "The class this function is called from is 'SMALL100Tokenizer'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import M2M100ForConditionalGeneration\n",
    "from utils.tokenization_small100 import SMALL100Tokenizer\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(\"alirezamsh/small100\")\n",
    "tokenizer = SMALL100Tokenizer.from_pretrained(\"alirezamsh/small100\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cherrypy\r\n",
      "  Downloading CherryPy-18.8.0-py2.py3-none-any.whl (348 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m348.4/348.4 kB\u001B[0m \u001B[31m36.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting cheroot>=8.2.1\r\n",
      "  Downloading cheroot-9.0.0-py2.py3-none-any.whl (100 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m100.6/100.6 kB\u001B[0m \u001B[31m23.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting jaraco.collections\r\n",
      "  Downloading jaraco.collections-3.8.0-py3-none-any.whl (10 kB)\r\n",
      "Collecting portend>=2.1.1\r\n",
      "  Downloading portend-3.1.0-py3-none-any.whl (5.3 kB)\r\n",
      "Collecting more-itertools\r\n",
      "  Downloading more_itertools-9.0.0-py3-none-any.whl (52 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m52.8/52.8 kB\u001B[0m \u001B[31m13.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting zc.lockfile\r\n",
      "  Downloading zc.lockfile-2.0-py2.py3-none-any.whl (9.7 kB)\r\n",
      "Collecting jaraco.functools\r\n",
      "  Downloading jaraco.functools-3.5.2-py3-none-any.whl (7.3 kB)\r\n",
      "Requirement already satisfied: six>=1.11.0 in /usr/lib/python3/dist-packages (from cheroot>=8.2.1->cherrypy) (1.14.0)\r\n",
      "Collecting tempora>=1.8\r\n",
      "  Downloading tempora-5.2.1-py3-none-any.whl (13 kB)\r\n",
      "Collecting jaraco.text\r\n",
      "  Downloading jaraco.text-3.11.1-py3-none-any.whl (11 kB)\r\n",
      "Collecting jaraco.classes\r\n",
      "  Downloading jaraco.classes-3.2.3-py3-none-any.whl (6.0 kB)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from zc.lockfile->cherrypy) (63.1.0)\r\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.9/dist-packages (from tempora>=1.8->portend>=2.1.1->cherrypy) (2022.1)\r\n",
      "Collecting autocommand\r\n",
      "  Downloading autocommand-2.2.2-py3-none-any.whl (19 kB)\r\n",
      "Collecting jaraco.context>=4.1\r\n",
      "  Downloading jaraco.context-4.3.0-py3-none-any.whl (5.3 kB)\r\n",
      "Collecting inflect\r\n",
      "  Downloading inflect-6.0.2-py3-none-any.whl (34 kB)\r\n",
      "Requirement already satisfied: pydantic>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from inflect->jaraco.text->jaraco.collections->cherrypy) (1.9.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from pydantic>=1.9.1->inflect->jaraco.text->jaraco.collections->cherrypy) (4.3.0)\r\n",
      "Installing collected packages: zc.lockfile, more-itertools, jaraco.context, autocommand, jaraco.functools, jaraco.classes, inflect, tempora, jaraco.text, cheroot, portend, jaraco.collections, cherrypy\r\n",
      "Successfully installed autocommand-2.2.2 cheroot-9.0.0 cherrypy-18.8.0 inflect-6.0.2 jaraco.classes-3.2.3 jaraco.collections-3.8.0 jaraco.context-4.3.0 jaraco.functools-3.5.2 jaraco.text-3.11.1 more-itertools-9.0.0 portend-3.1.0 tempora-5.2.1 zc.lockfile-2.0\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install cherrypy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import cherrypy\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class EntityLinker(object):\n",
    "    exposed = True\n",
    "    def GET(self, *path, **query):\n",
    "        no_text = query.get('text', None)\n",
    "        tokenizer.tgt_lang = \"en\"\n",
    "        encoded_no = tokenizer(no_text, return_tensors=\"pt\")\n",
    "        generated_tokens = model.generate(**encoded_no)\n",
    "        results = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        en_text = results[0]\n",
    "        list_entity = spans_to_mind_format(refined.process_text(title))\n",
    "        list_entity_json = json.dumps(list_entity)\n",
    "        return list_entity_json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/Feb/2023:16:14:21] ENGINE Bus STARTING\n",
      "[02/Feb/2023:16:14:21] ENGINE Started monitor thread 'Autoreloader'.\n",
      "[02/Feb/2023:16:14:21] ENGINE Serving on http://0.0.0.0:8099\n",
      "[02/Feb/2023:16:14:21] ENGINE Bus STARTED\n"
     ]
    }
   ],
   "source": [
    "conf = {\n",
    "    '/' : {'request.dispatch' : cherrypy.dispatch.MethodDispatcher() } # configuration of the path to address\n",
    "}\n",
    "cherrypy.tree.mount(EntityLinker(), '/linker', conf) # one for each object + passing the configuration\n",
    "\n",
    "cherrypy.config.update({'server.socket_host': '0.0.0.0'})\n",
    "cherrypy.config.update({'server.socket_port': 8099})\n",
    "\n",
    "cherrypy.engine.start()\n",
    "\n",
    "\n",
    "cherrypy.engine.block()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
