{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from train_test import *\n",
    "import argparse\n",
    "from utils.parse_config import ConfigParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Config Loading\n",
    "parser = argparse.ArgumentParser(description='KRED')\n",
    "parser.add_argument('-f')\n",
    "parser.add_argument('-c', '--config', default=\"./config.json\", type=str,\n",
    "                    help='config file path (default: None)')\n",
    "parser.add_argument('-r', '--resume', default=None, type=str,\n",
    "                    help='path to latest checkpoint (default: None)')\n",
    "parser.add_argument('-d', '--device', default=None, type=str,\n",
    "                    help='indices of GPUs to enable (default: all)')\n",
    "\n",
    "config = ConfigParser.from_args(parser)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils.util_jobs import load_pretrained_data_mind_jobs\n",
    "data = load_pretrained_data_mind_jobs(config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training\n",
      "Training epoch 0/6 - 0.0\n",
      "######\n",
      " Step: 0, 0.0 \n",
      "######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J:\\Downloads\\NLP\\kred\\model\\KGAT.py:143: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neighbor_entity_embedding = entity_embedding_lookup(torch.tensor(neighbor_entities).cuda())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######\n",
      " Step: 100, 0.14367816091954022 \n",
      "######\n",
      "######\n",
      " Step: 200, 0.28735632183908044 \n",
      "######\n",
      "######\n",
      " Step: 300, 0.43103448275862066 \n",
      "######\n",
      "######\n",
      " Step: 400, 0.5747126436781609 \n",
      "######\n",
      "######\n",
      " Step: 500, 0.7183908045977011 \n",
      "######\n",
      "######\n",
      " Step: 600, 0.8620689655172413 \n",
      "######\n",
      "all loss: tensor(284.8864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "_train_epoch\n",
      "auc socre: 0.8359618325034506\n",
      "valid_socre\n",
      "valid_scores\n",
      "early_stopping\n",
      "Saving checkpoint: out\\saved\\models\\KRED\\0216_151132\\checkpoint-model-epoch1.pth ...\n",
      "epoch % self.save_period\n",
      "Training epoch 1/6 - 0.16666666666666666\n",
      "######\n",
      " Step: 0, 0.0 \n",
      "######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J:\\Downloads\\NLP\\kred\\model\\KGAT.py:143: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  neighbor_entity_embedding = entity_embedding_lookup(torch.tensor(neighbor_entities).cuda())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######\n",
      " Step: 100, 0.14367816091954022 \n",
      "######\n",
      "######\n",
      " Step: 200, 0.28735632183908044 \n",
      "######\n",
      "######\n",
      " Step: 300, 0.43103448275862066 \n",
      "######\n",
      "######\n",
      " Step: 400, 0.5747126436781609 \n",
      "######\n",
      "######\n",
      " Step: 500, 0.7183908045977011 \n",
      "######\n",
      "######\n",
      " Step: 600, 0.8620689655172413 \n",
      "######\n",
      "all loss: tensor(182.1156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "_train_epoch\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m config[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrainer\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtraining_type\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msingle_task\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m----> 2\u001B[0m     \u001B[43msingle_task_training\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m      4\u001B[0m     multi_task_training(config, data)\n",
      "File \u001B[1;32mJ:\\Downloads\\NLP\\kred\\train_test.py:168\u001B[0m, in \u001B[0;36msingle_task_training\u001B[1;34m(config, data)\u001B[0m\n\u001B[0;32m    165\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moptimizer\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m'\u001B[39m], weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m    167\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(config, model, criterion, optimizer, device, train_data_loader, data[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m--> 168\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mJ:\\Downloads\\NLP\\kred\\trainer\\trainer.py:114\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_epoch(epoch)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_train_epoch\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m--> 114\u001B[0m valid_socre \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_valid_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalid_socre\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    116\u001B[0m valid_scores\u001B[38;5;241m.\u001B[39mappend(valid_socre)\n",
      "File \u001B[1;32mJ:\\Downloads\\NLP\\kred\\trainer\\trainer.py:79\u001B[0m, in \u001B[0;36mTrainer._valid_epoch\u001B[1;34m(self, epoch)\u001B[0m\n\u001B[0;32m     77\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     78\u001B[0m         end \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtest_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m---> 79\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mitem1\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43mstart\u001B[49m\u001B[43m:\u001B[49m\u001B[43mend\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mitem2\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43mstart\u001B[49m\u001B[43m:\u001B[49m\u001B[43mend\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     80\u001B[0m \u001B[43m                     \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrainer\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtask\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m[\n\u001B[0;32m     81\u001B[0m         \u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m     83\u001B[0m     y_pred\u001B[38;5;241m.\u001B[39mextend(out)\n\u001B[0;32m     84\u001B[0m truth \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtest_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32mJ:\\Downloads\\NLP\\PyEnv\\TorchEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mJ:\\Downloads\\NLP\\kred\\model\\KRED.py:64\u001B[0m, in \u001B[0;36mKREDModel.forward\u001B[1;34m(self, user_features, news_features, task)\u001B[0m\n\u001B[0;32m     61\u001B[0m         user_embedding \u001B[38;5;241m=\u001B[39m user_embedding\u001B[38;5;241m.\u001B[39mexpand(candidate_news_embedding\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], user_embedding\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m],\n\u001B[0;32m     62\u001B[0m                                            user_embedding\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m2\u001B[39m])\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 64\u001B[0m     user_embedding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muser_modeling\u001B[49m\u001B[43m(\u001B[49m\u001B[43muser_features\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     65\u001B[0m     candidate_news_embedding, topk_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnews_embedding(news_features)\n\u001B[0;32m     66\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(candidate_news_embedding\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlen\u001B[39m(user_embedding\u001B[38;5;241m.\u001B[39mshape):\n",
      "File \u001B[1;32mJ:\\Downloads\\NLP\\PyEnv\\TorchEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mJ:\\Downloads\\NLP\\kred\\model\\User_modeling.py:42\u001B[0m, in \u001B[0;36mUser_modeling.forward\u001B[1;34m(self, user_id)\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, user_id):\n\u001B[0;32m     41\u001B[0m     user_history \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_user_history(user_id)\n\u001B[1;32m---> 42\u001B[0m     user_history_embedding, top_indexs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnews_embedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43muser_history\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     43\u001B[0m     user_attention_modeling \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muser_attention_modeling(user_history_embedding)\n\u001B[0;32m     44\u001B[0m     user_embedding \u001B[38;5;241m=\u001B[39m user_attention_modeling\n",
      "File \u001B[1;32mJ:\\Downloads\\NLP\\PyEnv\\TorchEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mJ:\\Downloads\\NLP\\kred\\model\\News_embedding.py:172\u001B[0m, in \u001B[0;36mNews_embedding.forward\u001B[1;34m(self, news_id)\u001B[0m\n\u001B[0;32m    169\u001B[0m istitle_embedding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_title_embedding(istitle)\n\u001B[0;32m    170\u001B[0m type_embedding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_type_embedding(type_)\n\u001B[1;32m--> 172\u001B[0m kgat_entity_embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkgat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mentities\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# batch(news num) * entity num\u001B[39;00m\n\u001B[0;32m    173\u001B[0m news_entity_embedding \u001B[38;5;241m=\u001B[39m kgat_entity_embeddings \u001B[38;5;241m+\u001B[39m entity_num_embedding \u001B[38;5;241m+\u001B[39m istitle_embedding \u001B[38;5;241m+\u001B[39m type_embedding \u001B[38;5;66;03m#todo\u001B[39;00m\n\u001B[0;32m    175\u001B[0m aggregate_embedding, topk_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattention_layer(news_entity_embedding, context_vecs)\n",
      "File \u001B[1;32mJ:\\Downloads\\NLP\\PyEnv\\TorchEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mJ:\\Downloads\\NLP\\kred\\model\\KGAT.py:135\u001B[0m, in \u001B[0;36mKGAT.forward\u001B[1;34m(self, entity_ids)\u001B[0m\n\u001B[0;32m    132\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, entity_ids):\n\u001B[0;32m    133\u001B[0m     entity_ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mentity_ids_clearner(entity_ids)\n\u001B[1;32m--> 135\u001B[0m     neighbor_entities, neighbor_relations \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_neighbors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mentity_ids\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    138\u001B[0m     entity_embedding_lookup \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mEmbedding\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mentity_embedding\u001B[38;5;241m.\u001B[39mcuda())\n\u001B[0;32m    139\u001B[0m     relation_embedding_lookup \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mEmbedding\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelation_embedding\u001B[38;5;241m.\u001B[39mcuda())\n",
      "File \u001B[1;32mJ:\\Downloads\\NLP\\kred\\model\\KGAT.py:52\u001B[0m, in \u001B[0;36mKGAT.get_neighbors\u001B[1;34m(self, entities)\u001B[0m\n\u001B[0;32m     50\u001B[0m relation_adj_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madj_relation[entity_i]\n\u001B[0;32m     51\u001B[0m \u001B[38;5;66;03m# Some entities that are present in neighbor_entities does not exist in the embedding\u001B[39;00m\n\u001B[1;32m---> 52\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m index, (entity_i, relation_i) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mzip\u001B[39m(entity_adj_list, relation_adj_list)):\n\u001B[0;32m     53\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m entity_i \u001B[38;5;241m>\u001B[39m number_of_entities:\n\u001B[0;32m     54\u001B[0m         entity_adj_list\u001B[38;5;241m.\u001B[39mpop(index)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "if config['trainer']['training_type'] == \"single_task\":\n",
    "    single_task_training(config, data)\n",
    "else:\n",
    "    multi_task_training(config, data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data = data[-1]\n",
    "testing(test_data, config)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
